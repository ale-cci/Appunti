\documentclass[../template]{subfiles}

\begin{document}
\section{Memorie}
\subsection{Distinzione delle memorie}
Una memoria è un'unità logica, dedicata alla memorizzazione dei dati nel calcolatore.
Diversi tipi di memoria, sono classificate in base a 5 parametri:
\begin{itemize}
    \item Capacità: numero delle parole memorizzabili
        Chiamato $L$ il numero di linee, ed $N$ il numero di parole $L =\log_2 N$.
        Ogni parola è un dato ad $M$ bit.
        \\
        Dato che di solito $M = 8$, l'unità di misura la capacità di memoria si misura in byte.
    \item Caratteristiche fisiche:
        Di cui tipo (semiconduttore come RAM, a superficie magnetica HD, ottica DVD), il consumo,
        l'affidabilità misurata come MTBF (\textit{Mean Time Between Failure}), alterabilità (solo lettura o lettura/scrittura) e durevolezza (volatile o non-volatile)
    \item Organizzazione:
        memorie interne al calcolatore sono organizzate in una gerarchia,
        parallelismo ed interlacciamento (come si interfacciano con memorie di livello superiore)
    \item Modalità d'accesso: in quale modi si accede ai dati in memoria,
        \begin{itemize}
            \item Sequenziale: per accedere ad un dato in una posizione fissa è necessario leggere tutti i dati precedenti (cassette mangianastri)
            \item Diretto: è possibile accedere direttamente alla posizione in memoria, in molti casi però il tempo d'accesso è dipendente dalla posizione del dato rispetto alla posizione appena letta o scritta (cd)
            \item Casuale: un accesso diretto con tempo d'accesso costante (RAM, ROM)
            \item Associativo: si accedono agli indirizzi di memoria attraverso delle chiavi hash (tag), per controllare se un dato è presente vengono controllate tutte le locazioni esistenti.
        \end{itemize}

    \item Prestazioni:
        Per misurare le prestazioni di una memoria, esistono diversi parametri, uno di questi, come citato al punto precedente è il tempo d'accesso,  ovvero il tempo impiegato dalla memoria per raggiungere l'indirizzo da quando è fornito.

        Il tempo di ciclo $T_\text{rc}$ è definito come il tempo di accesso più il tempo necessario per terminare l'operazione prima di poter compiere un altro accesso.

        Mentre la velocità di trasferimento (bit rate) è l'inverso del tempo d'accesso, misurando il numero di bit trasferiti.

        Solitamente sono tutti dati imposti dalla CPU, a cui la memoria si adegua o introduce ritardi.

\end{itemize}

Il numero di pin in ingresso del componente della memoria non coincide necessariamente con $n_a$ ed $n_d$ del bus dei dati.
In un processore moderno, normalmente $n_a = 36$ quindi può indirizzare al massimo $64G$ di memoria RAM. Le dimensioni dell'unità di memoria può essere inferiore a $64G$, magari si hanno 4 memorie da $16G$, con $L=34$. $n_a$ rappresenta la massima memoria indirizzabile del processore, $L$ rappresenta la memoria effettiva di un cip specifico di memoria.

Le modalità d'accesso sono


\subsection{Gerarchie di memoria}
La memoria ideale sarebbe di capacità infinita, con tempo d'accesso, costo e consumo nullo.

L'insieme delle memorie presenti in un calcolatore mira a combinare le caratteristiche migliori di ogni tipo di memoria per raggiungere l'obbiettivo di memoria ideale.

Salendo la gerarchia diminuisce il tempo d'accesso e la capacità delle memorie e cresce il costo per bit.

Al livello più alto della gerarchia sono presenti i registri interni alla CPU, segue la cache, poi la memoria centrale o principale, ed in fondo alla gerarchia le memorie secondarie, con alte capacità ma bassi costi e permanenti.
\subsubsection{Principio di località}

Un programma in un certo istante $t$ necessita di determinati dati
Se un programma ad un istante $t$ accede ad un certo dato,
c'è alta probabilità che siano richiesti anche i dati adiacenti (proprietà di località spaziale), e che all'istante successivo si acceda nuovamente alla memoria (proprietà di località temporale).

Gli algoritmi della MMU (\textit{Memory Management Unit}) si concentrano a minimizzare il numero di accessi in memoria a livelli più bassi.


\subsubsection{Blocco di memoria}
Con blocco si fa riferimento all'unità di informazione minima scambiata fra i livelli di memoria.
Quando un particolare dato viene richiesto ad una memoria, l'evento che il dato non sia presente prende il nome di "miss" mentre se il dato è già presente si chiama "hit".
\\
Lo scopo di una buona gerarchia di memoria è massimizzare il rapporto tra hit e miss.
La frequenza di accessi trovati direttamente al livello superiore prende il nome di hit-rate ($h$).
La miss rate è quindi complementare a quest'ultimo.
\\
Il tempo per recuperare il dato al livello successivo in caso di miss prende il nome di "Miss Penalty", mentre se il dato è già disponibile, il tempo per recuperarlo è pari al tempo di hit.

Il miss penalty $T_{mp}$ può essere visto come la somma tra hit time ed il tempo richiesto per il trasferimento dei dati dai blocchi inferiori ($T_{miss}$).
\\
Ottenendo la relazione:
\[
    T_{acc} = h \cdot T_h + (1-h) T_{mp} = T_h + (1 -h) T_{miss}
\]
Dalla formula, minimizzando la miss rate, si tende alla memoria ideale, portando il tempo d'accesso uguale al tempo di hit.


\subsection{Gerarchie di memoria}
Una gerarchia di memoria è definita dai suoi livelli di memoria: il loro numero, dimensione, velocità e componenti.
\\
Il piazzamento del blocco, chiamato anche funzione di traduzione o di mapping, sceglie dove allocare il blocco nel livello di memoria corrente.  Nel caso della cache ad esempio è necessario calcolare un hash per determinarne la locazione.

L'identificazione come del blocco indica come risalire alla posizione del blocco di memoria.

Il rimpiazzamento si occupa di inserire i dati provenienti dai livelli inferiori della gerarchia, scegliendo in quale posizione del livello corrente inserirlo.

I dati, una volta modificati, vengono scritti sui livelli inferiori utilizzando strategie di scrittura.


Ad esempio, nel caso dei registri, l'identificazione è nominale, ed il nome viene indicato nel codice sorgente, mentre identificazione e rimpiazzamento sono definiti dal compilatore.

In memoria centrale, il piazzamento del blocco dipende dall'istruzizone (specificato dall'indirizzo di memoria), i dati sono identificati dall'indirizzo e le scritture sono scielte a livello di codice.

Le memorie centrali nei calcolatori sono le RAM, volatili e di lettura e scrittura). Di memorie RAM ci sono due categorie:
SRAM (\textit{Static RAM}) utilizzate per memorie cache e DRAM (\textit{Dynamic RAM}) utilizzate come memoria centrale.

Le memorie SRAM sono molto veloci e realizzate attraverso flip flop D, che permettono di memorizzare il dato senza la perdita.
La tecnologia richiesta per realizzare uno di questi flip flop è molto costosa, per questo al giorno d'oggi non è possibile utilizzare queste memorie per immagazzinare grandi quantità di dati.

Oltre ai flip flop in queste memorie sono presenti logiche di indrizzo e la selezione di lettura scrittura.

Le memoria DRAM ogni bit è rappresentato da un condensatore / transistor (nel caso di tecnologia mos). Il loro costo è molto inferiore quindi rispetto alle precedenti.
\\
Siccome i condensatori col tempo si scaricano, necessitano di circuiti automatici di refresh per ricaricare il condensatore.

Oltre a memorie RAM sono presenti le memorie ROM, a sola lettura. Esse sono divise in:
le ROM originali erano scrivibili un'unica volta e non sono volatili.
PROM (\textit{Programmable ROM}), scrivibili un'unica volta,
EPROM (\textit{Erasable PROM}), cancellabili attraverso la luce ultravioletta,
EEPROM (\textit{Electrically Erasable PROM}), cancellabili con segnali elettrici.
FLASH leggibili e scrivibili con dati non volatili (come SSD ).


% Lez 2
\subsubsection{Memorie SRAM}
Le SRAM, memorie ram statiche, sono RAM accedute come se fossero una matrice di dati.
Normalmente il singolo dato è rappresentato da flip flop D.

Per studiare un ciclo di lettura di una memoria statica, prendiamo come esempio una ram con $N=1024$ e $M = 4bit$.
Il numero di bit necessari ad indirizzare i valori è quindi $L = \log_2 N = 10$.
La RAM ha quindi ingressi e 2 segnali di controllo CS (\textit{Chip Select}) per abilitare il dispositivo e WE (\textit{Write enable}).

Una volta caricato l'indirizzo nel bus degli indirizzi, si abilita CS e dopo un tempo $T_{acc}$ il dato viene reso disponibile dalla memoria sul bus dei dati.

Per scrittura viene abilitato il write enable e caricato il dato da scrivere nel bus dei dati, ed al momento dell'abilitazione di CS, dopo un certo tempo il dato viene scritto in memoria.

Al termine di ogni operazione CS torna a 0, disabilitando il chip.
\subsubsection{Memorie DRAM}
Nel caso di ram dinamiche, tipicamente con capacità maggiore es $8Gb$ il numero di bit necessari per indirizzare i dati dovrebbe essere $L=33$, portando un numero di ingressi esagerato per un chip di memoria.
\\
La soluzione per accedere a questo tipi di memoria è dividere la capacità come una matrice bidimensionale, es una matrice di $2K$ righe e $4M$ colonne, ottenendo numero di bit di indirizzamento pari alla dimensione maggiore.
\\
Quindi le DRAM sono più lente rispetto alle SRAM, anche per la necessità di avere un secondo indirizzo per identificare il dato n memoria.

I due segnali per identificare gli indirizzi di una DRAM prendono il nome di RAS (\textit{Row Address Strobe}) e CAS (\textit{Column Address Strobe}).

RAS viene utilizzato per l'ingresso di un decoder,
RAS viene dato in ingresso ad un decoder, identificando con 1 la riga da leggere/scrivere. In un secondo momento il segnale CAS viene utilizzato come ingresso di un demultiplexer, selezionando la colonna in ingresso del relativo indirizzo.

Nel caso di lettura il segnale passa attraverso un buffer DOUT, inviando i dati al processore, nel caso di scrittura i dati vengono letti dal processore scrivendo il dato nella riga e colonna selezionati.

Qua sotto se mi ricordo di aggiungerla sarà presente lo schema funzionale di una memoria DRAM.

Contatore di refresh e circuito di refresh si sostituiscono agli indirizzi di riga per leggere gli indirizzi di memoria e ricaricare i condensatori.
OE è equivalente a CS.

\subsubsection{Lettura e scrittura DRAM}
La differenza fondamentale è la necessità di inserire un secondo indirizzo per identificare i dati.
Prima si inserisce il valore di RAS nel bus dei dati, abilitandone la lettura con RAS. Successivamente si inserisce CAS abilitandone la lettura con CAS. Al momento dell'abilitazione di CAS, RAS non viene disabilitato, (spiegazione successiva).
\\
Successivamente dopo un tempo di accesso, nel caso di lettura viene fornito sul bus dei dati il valore contenuto in memoria.

Quando entrambi i valori RAS e CAS sono disabilitati l'output è in 3-state, quindi non più modificabile.

Per effettuare le write è necessario che il segnale WE sia abilitato prima di abilitare il CAS, altrimenti il valore contenuto in memoria verrebbe copiato nel bus.

\subsubsection{SDRAM}
Sono sempre delle DRAM, realizzate con condensatori, con la differenza che sono sincrone.
Infatti se si guarda lo schema logico di una DRAM, non è presente un segnale di clock, effettuando ogni operazione sul fronte di salita/discesa del CAS.

Il vantaggio principale di questo tipo di memoria è la certezza di avere il dato in memoria dopo un numero preciso di cicli di clock. Cosa non sempre vera nel caso di memoria asincrona, dove il tempo richiesto è variabile.

Lo svantaggio che portano è visibile nel caso in cui i dati siano disponibili prima che il ciclo di clock sia completato.
Questo è compensato dal \textbf{trasferimento a burst}.

La CPU è infatti in grado di scegliere il numero di dati da fare ritornare alla memoria. Nel caso di trasferimento singolo, quando la memoria è interrogata torna un solo indirizzo. In caso di trasferimento a burst la memoria restituisce ad ogni ciclo di clock, il dato all'indirizzo di memoria successivo a quello specificato.

Ad esempio nel caso di accesso ad un file, il primo valore viene letto dopo 4 cicli di clock, mentre i successivi direttamente al ciclo di clock seguente.
Questa lettura a bus è fondamentale per riempire la cache interna.
% Schema funzionale SDRAM

\subsubsection{DDR}
Le DDR (\textit{Double Data Rate}) nascono come un ulteriore miglioramento delle SDRAM. Come dice il nome, leggono due dati in un unico ciclo di clock, campionando sia sul fronte di salita che sul fronte di discesa.

Il principio di funzionamento è identico.
\subsubsection{FPM-DRAM}
\textit{Fast Page Mode DRAM} permettono di tenere il segnale di RAS\# attivo, variando solo il segnale CAS\# in modo da velocizzare tutti gli accessi successivi al valore in memoria, ottenendo trasferimenti di tipo 6-3-3-3 O 5-3-3-3.

\subsubsection{EDO-DRAM}
\textit{Extended Data Out DRAM}, permettono di risparmiare cicli di clock per trasferimenti successivi, perché l'uscita non richiedevano di disabilitare l'uscita (WE) ad ogni lettura.

\subsubsection{RDRAM}
\textit{Rambus DRAM} (Rambus è il nome di un consorzio), sviluppate da Intel.
Permettevano di avere chip con fino a 320 pin con velocità di trasferimento di $1.6Gb/s$, trasferimento a blocchi stile Fast.
Chip con pin su un unico lato per ridurre il consumo di energia.
Utilizzate in schede video ad alte prestazioni.

\subsection{Memorie Permanenti}
Sono memorie a semiconduttore, non volatili.
Le memorie FLASH (realizzate in tecnologia NAND o NOR) sono utilizzate per chiavette USB e SSD.
NVSRAM (\textit{Non Voltaile SRAM}) non sono molto diffuse per via dell'elevato costo di produzione.
\subsubsection{FeRAM}
Le \textit{Ferroelectirc RAM}, chiamate anche FRAM o F-RAM, rientrano nelle tecnologie di memorie non volatili emergenti, ed attraverso uno strato di materiale ferroelettrico, permettendo la permanenza ai dati anche in caso di mancanza di corrente.

Rispetto alle memorie flash consumano meno energia, hanno una maggiore velocità di scrittura ed un numero di scrittura/cancellazione maggiore.
\subsubsection{PCM}
Le \textit{Phase Change memory} sono composte da materiale in grado di cambiare fase (cristallina o amorfa). In particolare una regione amorfa presenta bassa riflettività e una regione cristallina presenta alta riflettività, permettendo attraverso punte o laser di leggerne il contenuto (funzionamento simile a CD/DVD).

\subsubsection{MRAM}
Le \textit{Magnetoresisteive RAM}, sfruttano l'effetto magnetoresistivo, non memorizzando le informazioni come quantità di carica elettrica (Come le RAM), ma come un campo magnetico.
\\
La lettura dell'informazione è ottenuta attraverso la misura della resistenza elettrica della cella.

\subsubsection{RRAM/CBRAM}
La \textit{Conductive Bridging RAM} è basata sulle proprietà di un elettrolita solido (tipicamente solfuro di germanio drogato con rame) che posto tra un elettrodo relativamente inerte (esempio tungsteno, materiale delle lampadine a filo) ed uno elettrochimicamente attivo  come argento o rame, fa si che quando si applica un campo elettrico viene provocato uno spostamento di ioni metallici nell'elettrolita, formando dei "nano-fili" conduttivi.

I principali vantaggi di questa tecnologia sono il basso consumo, l'elevata velocità di scrittura e la lunga durata.
\end{document}
